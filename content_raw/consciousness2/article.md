# consciousness, freewill, AI

## my thoughts on consciousness

I look at consciousness as the thing that gives us a _point of view_, or
_point of experience_, which is more fundamental than feeling pain or joy.
We may call it the feeling of feeling at all, including the simple feeling
of observing things.

To demonstrate this further: if we imagine a robot with sensors, we can
programme it to read sensory data, process it, and react according to the
processed data in a seemingly sophisticated way that resembles the
behaviour of what we call an _animal_, or a form of _life_.

However, the question would remain:  does the robot really have its sensory
input connected to a point of experience?  Or is it simply a _blind_
action-reaction machine similar to the domino effect (but more complex)?
Why would the increased complexity suddenly grant the robot _point of
experience_?  I call an action-reaction _blind_ if I want to claim that it
is not attached to any point of view/experience/feeling.

Based on the fundamental particles in the standard physics model, I cannot
find any way that complexity could suddenly give rise to the feeling of
feeling, or the feeling of having inputs attached to a point of view.  I
can only find a collection of particles that explain the _blind_
action-reaction.

Since it seems that we cannot explain the existence of the point of
experience from the standard physics model, I'm lead to the following
hypothesis:

* If the _point of experience_ is not explainable by the existing particles
  in the standard physics model, then we have to introduce a new
  fundamental particle.  Let's call this new fundamental particle $x$.
* $x$ might be randomly roaming in space, in an attempt to find a
  complex-enough action-reaction machine, that is likely _blind_, in order
  to _attach_ to it.
* Once $x$ attaches to an action-reaction machine, it ends up connecting
  machine's _blind_ input to $x$'s input.

In this view, the reason we (e.g. humans) have a point of experience (or
feel of feeling, at all), is because each of us is an $x$ that is attached
to a complex enough action-reaction machine that is our physical/material
human body.  In a sense, we are an $x$ that's controlling seeing through
the sensors of this body, which is why we feel that we have a point of
experience.


## my thoughts on freewill


If we look at how machines react based on observations, from the
perspective of physics standard model, we could say that there is no source
of unpredictability (i.e. no choice) except if _quantum randomness_ is
real.  So, I think, for an observer in this universe, our freewill (if a
thing) comes from quantum randomness.

If there is no such a thing as quantum randomness, then we are effectively
saying that everything is explainable as a reaction to a previous action,
with no new decisions to be made, as everything is already decided by
previous actions.  Therefore, freewill necessarily requires quantum
randomness to be true.

If we analyse _randomness_, fundamentally, it is essentially when we fail
to explain an outcome due to us lacking information.  Such lack of
information could possibly be due to our ignorance of the laws of the
universe, or be due to the _source_ of it being outside of what we can
observe in this material universe.


## how might consciousness relate to freewill

Once $x$ attaches to the particles that make up our body), $x$ is able to
read our sensory data and feel it from its view (hence we get the point of
view).

Then, $x$ could manipulate the particles in our body to behave in some way,
to cause us to react to some events in ways that $x$ wants.  Here, we can
think that $x$ is the source of our freewill.

Since $x$ is not observable by our sensors, all we can see is some
unexplained randomness at the quantum level.

This way, we can see the idea of $x$ and freewill can be consistent, and
offer an explanation on why we might have a seemingly _absolute_
randomness at the quantum scale.

In other words, introducing $x$ as a fundamental particle can explain:
- Why we experience having a point of experience (consciousness).
- Why we might have freewill.
- Why we might be unable to explain at least part of the quantum randomness
  (because it is the freewill of $x$ manipulating our particles to make our
  material body react to events that $x$ has observed by getting attached
  to our material sensors).


## does AI have consciousness?

It might if it gets an $x$ attached to it.  But since we are unable to
observe $x$ by our material sensors, we might never know, as all the output
behaviour that we observe from $x$ is what appears to us as quantum
randomness.

Can we design a physical experiment to set $x$'s freewill responses apart from
the other unexplained quantum randomness?  I don't know.

A related concept to this test might be:  does $x$ behave in a way that
relates to what it observed in the past?  I.e. does $x$ even have memory?

We know that we feel that we have a memory, and the memory that we feel is
entirely in our material brain.  E.g. if we remove bits of someone's brain,
the person would start to lose his memory as we remove more of his brain
(this is what happens to people with brain strokes).

However, does this mean that $x$ also lacks a memory?  It is possible that
$x$ lacks a memory, and that all it used our material organs (mainly
brains' neurons) to store all its memory.


## a possible relation to simulated universe

$x$ could be a normal life form with consciousness and freewill in a
different parent universe that got attached to this simulation (our
universe) somehow, and was given control of the particles that make up our
body.

Then, in order to, say, test $x$'s behaviour in this simulation, it got its
native memory (in the real universe) erased (or disconnected temporarily).
Instead, it was given the ability to build a new memory in the simulation
(the material brain of the body that $x$ go attached to in this universe).

Why was $x$ attached to this simulation in this way?  There could be
several reasons, one of which could be that such simulations can be cheaper
and more accurate than the legal system.  For example, maybe $x$ committed
a crime, and in order to find out whether he is guilty, he got attached to
a simulation of a life similar to the crime scene, that is realistic
enough, in order to test his response.  In order to make the simulation
work as a fair test, $x$'s memory had to be erased.
